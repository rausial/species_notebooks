{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Integración-de-datos\" data-toc-modified-id=\"Integración-de-datos-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Integración de datos</a></span></li><li><span><a href=\"#Definición-de-funciones\" data-toc-modified-id=\"Definición-de-funciones-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Definición de funciones</a></span><ul class=\"toc-item\"><li><span><a href=\"#get_species_data\" data-toc-modified-id=\"get_species_data-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>get_species_data</a></span></li><li><span><a href=\"#get_sdm\" data-toc-modified-id=\"get_sdm-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>get_sdm</a></span></li><li><span><a href=\"#evaluate_sdms\" data-toc-modified-id=\"evaluate_sdms-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>evaluate_sdms</a></span></li><li><span><a href=\"#get_grid_iucn_intersection\" data-toc-modified-id=\"get_grid_iucn_intersection-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>get_grid_iucn_intersection</a></span></li><li><span><a href=\"#print_eval_stats\" data-toc-modified-id=\"print_eval_stats-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>print_eval_stats</a></span></li><li><span><a href=\"#plot_confussion_maps\" data-toc-modified-id=\"plot_confussion_maps-2.6\"><span class=\"toc-item-num\">2.6&nbsp;&nbsp;</span>plot_confussion_maps</a></span></li><li><span><a href=\"#plot_confusion_map\" data-toc-modified-id=\"plot_confusion_map-2.7\"><span class=\"toc-item-num\">2.7&nbsp;&nbsp;</span>plot_confusion_map</a></span></li><li><span><a href=\"#plot_maps_comparision\" data-toc-modified-id=\"plot_maps_comparision-2.8\"><span class=\"toc-item-num\">2.8&nbsp;&nbsp;</span>plot_maps_comparision</a></span></li><li><span><a href=\"#plot_bottom_mid_top_maps\" data-toc-modified-id=\"plot_bottom_mid_top_maps-2.9\"><span class=\"toc-item-num\">2.9&nbsp;&nbsp;</span>plot_bottom_mid_top_maps</a></span></li><li><span><a href=\"#get_stats_per_species\" data-toc-modified-id=\"get_stats_per_species-2.10\"><span class=\"toc-item-num\">2.10&nbsp;&nbsp;</span>get_stats_per_species</a></span></li><li><span><a href=\"#full_analysis\" data-toc-modified-id=\"full_analysis-2.11\"><span class=\"toc-item-num\">2.11&nbsp;&nbsp;</span>full_analysis</a></span></li><li><span><a href=\"#get_comparison_sdms\" data-toc-modified-id=\"get_comparison_sdms-2.12\"><span class=\"toc-item-num\">2.12&nbsp;&nbsp;</span>get_comparison_sdms</a></span></li><li><span><a href=\"#compare_eval_stats\" data-toc-modified-id=\"compare_eval_stats-2.13\"><span class=\"toc-item-num\">2.13&nbsp;&nbsp;</span>compare_eval_stats</a></span></li><li><span><a href=\"#print_confusion_matrix\" data-toc-modified-id=\"print_confusion_matrix-2.14\"><span class=\"toc-item-num\">2.14&nbsp;&nbsp;</span>print_confusion_matrix</a></span></li></ul></li><li><span><a href=\"#Análisis-a-64-km\" data-toc-modified-id=\"Análisis-a-64-km-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Análisis a 64 km</a></span><ul class=\"toc-item\"><li><span><a href=\"#Descripción\" data-toc-modified-id=\"Descripción-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Descripción</a></span></li><li><span><a href=\"#Resultados\" data-toc-modified-id=\"Resultados-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Resultados</a></span><ul class=\"toc-item\"><li><span><a href=\"#Desempeño-promedio\" data-toc-modified-id=\"Desempeño-promedio-3.2.1\"><span class=\"toc-item-num\">3.2.1&nbsp;&nbsp;</span>Desempeño promedio</a></span></li><li><span><a href=\"#Comparación-de-mapas-de-confusión\" data-toc-modified-id=\"Comparación-de-mapas-de-confusión-3.2.2\"><span class=\"toc-item-num\">3.2.2&nbsp;&nbsp;</span>Comparación de mapas de confusión</a></span></li></ul></li></ul></li><li><span><a href=\"#Análisis-a-&lt;span id='python_2b0f7ec5f4914808aff1cdc8ac058760_111'&gt;&lt;/span&gt;-km\" data-toc-modified-id=\"Análisis-a-<span id='python_2b0f7ec5f4914808aff1cdc8ac058760_19'></span>-km-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Análisis a <span id=\"python_2b0f7ec5f4914808aff1cdc8ac058760_51\"></span> km</a></span><ul class=\"toc-item\"><li><span><a href=\"#Descripción\" data-toc-modified-id=\"Descripción-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Descripción</a></span></li><li><span><a href=\"#Resultados\" data-toc-modified-id=\"Resultados-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Resultados</a></span><ul class=\"toc-item\"><li><span><a href=\"#Desempeño-promedio\" data-toc-modified-id=\"Desempeño-promedio-4.2.1\"><span class=\"toc-item-num\">4.2.1&nbsp;&nbsp;</span>Desempeño promedio</a></span></li></ul></li></ul></li><li><span><a href=\"#Análisis-a-&lt;span id='python_963b8b58b6fa46ad8d59a306fbb96cc9_111'&gt;&lt;/span&gt;-km\" data-toc-modified-id=\"Análisis-a-<span id='python_963b8b58b6fa46ad8d59a306fbb96cc9_19'></span>-km-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Análisis a <span id=\"python_963b8b58b6fa46ad8d59a306fbb96cc9_51\"></span> km</a></span><ul class=\"toc-item\"><li><span><a href=\"#Descripción\" data-toc-modified-id=\"Descripción-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Descripción</a></span></li><li><span><a href=\"#Resultados\" data-toc-modified-id=\"Resultados-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Resultados</a></span><ul class=\"toc-item\"><li><span><a href=\"#Desempeño-promedio\" data-toc-modified-id=\"Desempeño-promedio-5.2.1\"><span class=\"toc-item-num\">5.2.1&nbsp;&nbsp;</span>Desempeño promedio</a></span></li></ul></li></ul></li><li><span><a href=\"#Análisis-con-todas-las-especies-(439)-a-64,-32-y-16-km\" data-toc-modified-id=\"Análisis-con-todas-las-especies-(439)-a-64,-32-y-16-km-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Análisis con todas las especies (439) a 64, 32 y 16 km</a></span><ul class=\"toc-item\"><li><span><a href=\"#Modelo-con-variables-climáticas-(WorldClim-1.4),-registros-de-mamíferos-(clase-Mammalia)-y-plantas-con-flor-(clase-Magnoliopsida)\" data-toc-modified-id=\"Modelo-con-variables-climáticas-(WorldClim-1.4),-registros-de-mamíferos-(clase-Mammalia)-y-plantas-con-flor-(clase-Magnoliopsida)-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Modelo con variables climáticas (WorldClim 1.4), registros de mamíferos (clase Mammalia) y plantas con flor (clase Magnoliopsida)</a></span><ul class=\"toc-item\"><li><span><a href=\"#64-km\" data-toc-modified-id=\"64-km-6.1.1\"><span class=\"toc-item-num\">6.1.1&nbsp;&nbsp;</span>64 km</a></span></li><li><span><a href=\"#32-km\" data-toc-modified-id=\"32-km-6.1.2\"><span class=\"toc-item-num\">6.1.2&nbsp;&nbsp;</span>32 km</a></span></li><li><span><a href=\"#16-km\" data-toc-modified-id=\"16-km-6.1.3\"><span class=\"toc-item-num\">6.1.3&nbsp;&nbsp;</span>16 km</a></span></li></ul></li><li><span><a href=\"#Modelo-con-variables-climáticas-(WorldClim-1.4)\" data-toc-modified-id=\"Modelo-con-variables-climáticas-(WorldClim-1.4)-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>Modelo con variables climáticas (WorldClim 1.4)</a></span><ul class=\"toc-item\"><li><span><a href=\"#64-km\" data-toc-modified-id=\"64-km-6.2.1\"><span class=\"toc-item-num\">6.2.1&nbsp;&nbsp;</span>64 km</a></span></li><li><span><a href=\"#32-Km\" data-toc-modified-id=\"32-Km-6.2.2\"><span class=\"toc-item-num\">6.2.2&nbsp;&nbsp;</span>32 Km</a></span></li><li><span><a href=\"#16-km\" data-toc-modified-id=\"16-km-6.2.3\"><span class=\"toc-item-num\">6.2.3&nbsp;&nbsp;</span>16 km</a></span></li></ul></li><li><span><a href=\"#Analisis-con-todos-los-animales-y-todas-las-plantas\" data-toc-modified-id=\"Analisis-con-todos-los-animales-y-todas-las-plantas-6.3\"><span class=\"toc-item-num\">6.3&nbsp;&nbsp;</span>Analisis con todos los animales y todas las plantas</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Magics\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "#utils\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "# Web\n",
    "import requests\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry\n",
    "import json\n",
    "\n",
    "# Stats\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score\n",
    "from sklearn.metrics import recall_score, classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "# GIS libs\n",
    "import folium\n",
    "import folium.plugins\n",
    "import fiona # for reading and writing shapefiles\n",
    "import geopandas as gpd\n",
    "\n",
    "import os\n",
    "import math\n",
    "\n",
    "# visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "sns.set()\n",
    "\n",
    "def requests_retry_session(\n",
    "    retries=3,\n",
    "    backoff_factor=0.3,\n",
    "    status_forcelist=(500, 502, 504),\n",
    "    session=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Source: https://www.peterbe.com/plog/best-practice-with-retries-with-requests\n",
    "    \"\"\"\n",
    "    session = session or requests.Session()\n",
    "    retry = Retry(\n",
    "        total=retries,\n",
    "        read=retries,\n",
    "        connect=retries,\n",
    "        backoff_factor=backoff_factor,\n",
    "        status_forcelist=status_forcelist,\n",
    "    )\n",
    "    adapter = HTTPAdapter(max_retries=retry)\n",
    "    session.mount('http://', adapter)\n",
    "    session.mount('https://', adapter)\n",
    "    return session\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integración de datos\n",
    "\n",
    "La primer tarea es extraer la información en el shape de IUCN y crear malla de presencia y ausencia para comparar los resultados de un modelo climático de SPECIES. Utilizaremos una resolución de 64km por lado de celda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargamos el mapa de IUCN\n",
    "iucn_shp = gpd.read_file('data/IUCN/TERRESTRIAL_MAMMALS/TERRESTRIAL_MAMMALS.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iucn_shp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargamos la malla de Mexico\n",
    "analysis_res = 64\n",
    "grid_path = os.path.join(\"grids/\", \"mx_grid_{}km.json\".format(analysis_res))\n",
    "grid = gpd.read_file(grid_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = grid.plot(color='blue')\n",
    "iucn_shp.plot(ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez cargado el shape de IUCN necesitamos iterar sobre cada especie. Para cada especie obtenemos las celdas que ocupa y deberíamos agregar esas precencias a una mega PAM. La PAM tendrá un renglón por especie y una columna por celda (especies x celdas). Esta es una matriz dispersa (checar opciones para manejar este tipo de matrices p.ej en scypy). Los indices de la PAM los deberíamos mapear a nombres de especie y ids de celda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nota: En MacOSX tuve que instalar rtree y spatialindex para que funcionara gpd.sjoin:\n",
    "* pip install rtree\n",
    "* brew install spatialindex\n",
    "\n",
    "También hubo que reinstalar fiona y shapely desde código fuente porque aparecía el error: \n",
    "    \n",
    "    Assertion failed: (0), function query, file AbstractSTRtree.cpp, line 285.\n",
    "* pip install --no-binary :all: fiona\n",
    "* pip install --no-binary :all: shapely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time presence_cells = gpd.sjoin(grid, iucn_shp, op='intersects', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "presence_cells.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agrupamos por especie el DF de presencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_cells = presence_cells.groupby(by='binomial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iucn_data = sp_cells.get_group('Ammospermophilus interpres')\n",
    "iucn_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para cada especie tenemos un mapa que tomamos como la verdad sobre la distribución de la especie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = grid.plot(facecolor='none', edgecolor='k')\n",
    "iucn_data.plot(ax=ax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_api = 'http://species.conabio.gob.mx/api/niche/'\n",
    "endpoint = 'getCellScore'\n",
    "params = \"id=27923&idtime=1525302357735&apriori=apriori&min_occ=5&fossil=false&mapa_prob=mapa_prob&sfecha=false&val_process=false&idtabla=no_table&grid_res=64&tfilters%5B0%5D%5Bvalue%5D=root_bioclim&tfilters%5B0%5D%5Btype%5D=0&tfilters%5B0%5D%5Blevel%5D=0&tfilters%5B0%5D%5Blabel%5D=Bioclim&tfilters%5B1%5D%5Bfield%5D=clasevalida&tfilters%5B1%5D%5Bvalue%5D=Mammalia&tfilters%5B1%5D%5Btype%5D=4&tfilters%5B2%5D%5Bfield%5D=clasevalida&tfilters%5B2%5D%5Bvalue%5D=Magnoliopsida&tfilters%5B2%5D%5Btype%5D=4&hasBios=true&hasRaster=true\"\n",
    "\n",
    "query = \"{}{}?{}\".format(url_api, endpoint, params)\n",
    "r = requests.get(query)\n",
    "data = json.loads(r.content)\n",
    "data = data['data']\n",
    "data = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sdm_2 = get_sdm(api_url, 27923, analysis_res=64, bioclim_groups=bioclim_groups, biotic_groups=biotic_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdm_2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdm = grid.merge(data, on='gridid')\n",
    "sdm.tscore = pd.to_numeric(sdm.tscore)\n",
    "sdm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdm_eval = sdm.merge(iucn_data[['gridid', 'presence']], on='gridid', how='left')\n",
    "sdm_eval['presence'] = sdm_eval['presence'].fillna(0).astype(int)\n",
    "sdm_eval['pred'] = sdm_eval['tscore'].round(0).astype(int)\n",
    "\n",
    "sdm_eval['confussion'] = 2*sdm_eval['presence'] + sdm_eval['pred']\n",
    "labels = {\n",
    "    0: 'True negative',\n",
    "    1: 'False possitive',\n",
    "    2: 'False negative',\n",
    "    3: 'True possitive'\n",
    "}\n",
    "sdm_eval['confussion_labels'] = [labels[conf_val] for conf_val in sdm_eval['confussion']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdm_eval[sdm_eval['confussion'] == 3].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, figsize=(10, 6))\n",
    "ax.set_title(u'Mapa de confusión')\n",
    "sdm_eval.plot(ax=ax,\n",
    "              column='confussion_labels',\n",
    "              cmap='Set3',\n",
    "              alpha=0.9,\n",
    "              edgecolor='w',\n",
    "              legend=True,\n",
    "              categorical=True)\n",
    "ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy: ', accuracy_score(sdm_eval.presence, sdm_eval.pred))\n",
    "print('F1 score: ', f1_score(sdm_eval.presence, sdm_eval.pred))\n",
    "print('Recall: ', recall_score(sdm_eval.presence, sdm_eval.pred))\n",
    "print('Precision: ', precision_score(sdm_eval.presence, sdm_eval.pred))\n",
    "print('\\n clasification report: \\n', classification_report(sdm_eval.presence, sdm_eval.pred))\n",
    "print('\\n confussion matrix: \\n',confusion_matrix(sdm_eval.presence, sdm_eval.pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definición de funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_url = 'http://species.conabio.gob.mx/api/niche'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get_species_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_species_data(api_url, name, analysis_res=16):\n",
    "    \"\"\" Regresa un dataframe con la información taxonomica de una especie y su id en la base de datos  \"\"\"\n",
    "    query = {\n",
    "        \"searchStr\":name, # Nombre de la especie substring de la especie a buscar\n",
    "        \"source\":1,        \n",
    "        \"limit\": \"true\",\n",
    "        \"grid_res\": 16\n",
    "    }\n",
    "    r = requests.post(api_url+'/especie/getEntList', params=query)\n",
    "\n",
    "    response = json.loads(r.content)\n",
    "    return pd.DataFrame(response['data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get_sdm\n",
    "Obtener un modelo de distribución utilizando el API de SPECIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sdm(api_url, sp_id, analysis_res=32, bioclim_groups={}, biotic_groups={}, verbose=False):\n",
    "    endpoint = 'getCellScore'\n",
    "    has_raster = 'false'\n",
    "    has_bios = 'false'\n",
    "    \n",
    "    params = {\n",
    "        \"id\": \"{}\".format(sp_id),\n",
    "        \"lim_inf\": \"1940\",\n",
    "        \"lim_sup\": \"2020\",\n",
    "        \"idtime\": \"1525302357735\",\n",
    "        \"apriori\": \"apriori\",\n",
    "        \"min_occ\": \"5\",\n",
    "        \"fossil\": \"false\",\n",
    "        \"mapa_prob\": \"mapa_prob\",\n",
    "        \"sfecha\": \"false\",\n",
    "        \"val_process\": \"false\",\n",
    "        \"idtabla\": \"no_table\",\n",
    "        \"grid_res\": \"{}\".format(analysis_res),\n",
    "    }\n",
    "    \n",
    "    if bioclim_groups:\n",
    "        has_raster = 'true'\n",
    "        for i, k in enumerate(bioclim_groups.keys()):\n",
    "            value = bioclim_groups[k]\n",
    "            abio_type = str(0)\n",
    "            abio_level = str(0)\n",
    "            abio_label = k\n",
    "            params.update({\n",
    "              \"tfilters[{}][value]\".format(i): value,\n",
    "              \"tfilters[{}][type]\".format(i): abio_type,\n",
    "              \"tfilters[{}][level]\".format(i): abio_level,\n",
    "              \"tfilters[{}][label]\".format(i): abio_label,  \n",
    "            })\n",
    "    if biotic_groups:\n",
    "        offset = len(bioclim_groups)\n",
    "        has_bios = 'true'\n",
    "\n",
    "        for i, k in enumerate(biotic_groups.keys()):\n",
    "            index = i + offset\n",
    "            field = biotic_groups[k]\n",
    "            value = k \n",
    "            bio_type = str(4)\n",
    "            params.update({\n",
    "                \"tfilters[{}][field]\".format(index): field,\n",
    "                \"tfilters[{}][value]\".format(index): value,\n",
    "                \"tfilters[{}][type]\".format(index): bio_type\n",
    "            })\n",
    "    params.update({\n",
    "        \"hasBios\": has_bios,\n",
    "        \"hasRaster\": has_raster\n",
    "    })\n",
    "    \n",
    "    query = api_url + \"/{}\".format(endpoint)\n",
    "    r = requests_retry_session(retries=10).post(query, params, timeout=200)\n",
    "        \n",
    "    data = json.loads(r.content)\n",
    "    data = data['data']\n",
    "\n",
    "    data = pd.DataFrame(data)\n",
    "    if data.empty:\n",
    "        print('No data')\n",
    "    else:\n",
    "        data.tscore = pd.to_numeric(data.tscore)    \n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluate_sdms\n",
    "\n",
    "Esta función obtiene modelos de distribución para las especies $e_i$, donde $i$ es tal que $start \\leq i \\lt end$, y etiqueta cada resultado como 'True possitive', 'True negative', 'False possitive', ó, 'False negative' de acuerdo a los  modelos de distribución de referencia (**sp_cells**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_sdms(api_url, sp_cells, grid,\n",
    "                  analysis_res = 64, start = 0, end = 20,\n",
    "                  bioclim_groups = {}, biotic_groups = {},\n",
    "                  verbose = False,\n",
    "                  checkpoints_frq = None, checkpoints_prefix = '', load_check = None):\n",
    "    iter_count = 0\n",
    "    sp_dfs = {}\n",
    "    labels = {\n",
    "        0: 'True negative',\n",
    "        1: 'False possitive',\n",
    "        2: 'False negative',\n",
    "        3: 'True possitive'\n",
    "    }\n",
    "    prev_checkpoint = None\n",
    "    \n",
    "    if load_check:\n",
    "        saved_checkpoint = \"{}sdms_dict_{}.pkl\".format(checkpoints_prefix, load_check)\n",
    "        with open(saved_checkpoint, 'rb') as in_file:\n",
    "            sp_dfs = pickle.load(in_file)\n",
    "            print(\"{} species loaded.....\".format(len(sp_dfs)))\n",
    "            prev_checkpoint = saved_checkpoint \n",
    "    try:                \n",
    "        for name, group in sp_cells:\n",
    "            if iter_count >= end:\n",
    "                break\n",
    "                \n",
    "            iter_count += 1\n",
    "            if sp_dfs.has_key(name):\n",
    "                print('Skipping ', name)   \n",
    "            else:\n",
    "                if verbose:\n",
    "                    print(name)\n",
    "\n",
    "                truth = group\n",
    "                species_data = get_species_data(api_url, name, analysis_res)\n",
    "\n",
    "                if {'spid'}.issubset(species_data.columns):\n",
    "                    spid = species_data['spid'][0]\n",
    "                    sdm = get_sdm(api_url,\n",
    "                                  spid,\n",
    "                                  analysis_res = analysis_res,\n",
    "                                  bioclim_groups = bioclim_groups,\n",
    "                                  biotic_groups = biotic_groups,\n",
    "                                  verbose = verbose)\n",
    "\n",
    "                    if not sdm.empty:\n",
    "                        sdm = grid.merge(sdm, on='gridid')\n",
    "                        sdm['species'] = name\n",
    "\n",
    "                        sdm_eval = sdm.merge(truth[['gridid', 'presence']], on='gridid', how='left')\n",
    "                        if {'tscore'}.issubset(sdm_eval.columns):\n",
    "                            sdm_eval['presence'] = sdm_eval['presence'].fillna(0).astype(int)            \n",
    "                            sdm_eval['pred'] = sdm_eval['tscore'].round(0).astype(int)\n",
    "                            sdm_eval.loc[sdm_eval.presence > 2, 'presence'] = 0\n",
    "                            sdm_eval.loc[sdm_eval.presence == 2, 'presence'] = 1\n",
    "                            sdm_eval['confussion'] = 2*sdm_eval['presence'] + sdm_eval['pred']\n",
    "                            sdm_eval['confussion_labels'] = [labels[conf_val] for conf_val in sdm_eval['confussion']]\n",
    "                            sp_dfs[name] = sdm_eval\n",
    "\n",
    "                            if checkpoints_frq and len(sp_dfs) % checkpoints_frq == 0:\n",
    "                                print(\"Num. Especies: \", len(sp_dfs))\n",
    "                                new_checkpoint = '{}sdms_dict_{}.pkl'.format(checkpoints_prefix, len(sp_dfs))\n",
    "                                \n",
    "                                with open(new_checkpoint, 'wb') as out_file:\n",
    "                                    pickle.dump(sp_dfs, out_file, pickle.HIGHEST_PROTOCOL)                                                                 \n",
    "                                if prev_checkpoint and os.path.exists(prev_checkpoint):\n",
    "                                    os.remove(prev_checkpoint)\n",
    "                                prev_checkpoint = new_checkpoint\n",
    "                    else:\n",
    "                        # if empty\n",
    "                        sp_dfs[name] = pd.DataFrame()\n",
    "                                \n",
    "    except requests.exceptions.RequestException as err:\n",
    "        print(\"Error de conexión: \", err)\n",
    "        return pd.concat(sp_dfs)                \n",
    "    finally:\n",
    "        print(\"Final Num. Especies: \", len(sp_dfs))\n",
    "        new_checkpoint = '{}sdms_dict_{}.pkl'.format(checkpoints_prefix, len(sp_dfs))\n",
    "\n",
    "        with open(new_checkpoint, 'wb') as out_file:\n",
    "            pickle.dump(sp_dfs, out_file, pickle.HIGHEST_PROTOCOL)                                                                 \n",
    "\n",
    "    return pd.concat(sp_dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get_grid_iucn_intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grid_iucn_intersection(grid_dir, analysis_res, iucn_shp):\n",
    "    grid_path = os.path.join(grid_dir, \"mx_grid_{}km.json\".format(analysis_res))\n",
    "    grid = gpd.read_file(grid_path)\n",
    "    \n",
    "    presence_cells = gpd.sjoin(iucn_shp, grid, how='right', op='intersects')\n",
    "    sp_cells = presence_cells.groupby(by='binomial')\n",
    "    \n",
    "    return sp_cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## print_eval_stats\n",
    "Para evaluar el desempeño reportamos la precisión, cobertura, exactitud y score F1. Las definiciones de estas estadísticas son:\n",
    "\n",
    "Sean\n",
    "* $tp$ los verdaderos positivos\n",
    "* $tn$ los verdaderos negativos\n",
    "* $fp$ los falsos positivos\n",
    "* $fn$ los falsos negativos\n",
    "\n",
    "entonces definimos la precisión, el recall, la exactitud (accuracy), y el score f1 de la siguiente manera:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "precision &= \\frac{tp}{tp + fp} \\\\\n",
    "recall &= \\frac{tp}{tp + fn} \\\\\n",
    "accuracy &= \\frac{tp + tn}{tp + fp + tn + fn} \\\\\n",
    "f1 &= \\frac{2}{\\frac{1}{precision} + \\frac{1}{recall}}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_eval_stats(sdms_df):\n",
    "    fig = print_confusion_matrix(confusion_matrix(sdms_df.presence, sdms_df.pred), class_names=[0, 1])\n",
    "    plt.show(fig)\n",
    "    print('Accuracy: ', accuracy_score(sdms_df.presence, sdms_df.pred))\n",
    "    print('F1 score: ', f1_score(sdms_df.presence, sdms_df.pred))\n",
    "    print('Recall: ', recall_score(sdms_df.presence, sdms_df.pred))\n",
    "    print('Precision: ', precision_score(sdms_df.presence, sdms_df.pred))\n",
    "    print('\\n clasification report: \\n', classification_report(sdms_df.presence, sdms_df.pred))\n",
    "        \n",
    "    stats = get_stats_per_species(sdms_df)\n",
    "    df = pd.DataFrame(stats)\n",
    "    df_test = pd.melt(df[['f1', 'acc', 'recall', 'precision']], var_name=['estadistica'], value_name='valor')\n",
    "    g = sns.FacetGrid(df_test, col='estadistica', size=4)\n",
    "    g.map(sns.distplot, 'valor', bins=10, kde=True, rug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot_confussion_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confussion_maps(sdms_df, num_plots, title=''):\n",
    "    flatui = ['#ca0020','#f4a582','#92c5de','#0571b0']\n",
    "    my_cmap = ListedColormap(sns.color_palette(flatui).as_hex())\n",
    "    \n",
    "    nrows = num_plots // 3\n",
    "    f, axes = plt.subplots(nrows=nrows, ncols=3, figsize=(20, nrows*4))\n",
    "    sp_grp = sdms_df.groupby('species')\n",
    "\n",
    "    axes = axes.flat\n",
    "    ax_num = 0\n",
    "\n",
    "    for name, grp in sp_grp:\n",
    "        if ax_num >= len(axes):\n",
    "            break\n",
    "        ax = axes[ax_num]\n",
    "        ax_num += 1\n",
    "        acc = accuracy_score(grp.presence, grp.pred)\n",
    "        f1 = f1_score(grp.presence, grp.pred)\n",
    "        recall = recall_score(grp.presence, grp.pred)\n",
    "        prec = precision_score(grp.presence, grp.pred)\n",
    "        ax.set_title('{} {}: acc={}, f1={}, r={}, p={}'.format(\n",
    "            title, name, round(acc, 2), round(f1, 2), round(recall, 2), round(prec, 2)), loc=\"left\")\n",
    "        \n",
    "        grp.plot(ax=ax,\n",
    "                  column='confussion_labels',\n",
    "                  alpha=0.9,\n",
    "                  edgecolor='w',\n",
    "                  legend=True,\n",
    "                  categorical=True,\n",
    "                  cmap=my_cmap)\n",
    "        ax.set_axis_off()\n",
    "\n",
    "    f.tight_layout()\n",
    "    return f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot_confusion_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_map(sp_model, ax, name='', title=''):\n",
    "    flatui = ['#ca0020','#f4a582','#92c5de','#0571b0']\n",
    "    my_cmap = ListedColormap(sns.color_palette(flatui).as_hex())\n",
    "    \n",
    "    acc = accuracy_score(sp_model.presence, sp_model.pred)\n",
    "    f1 = f1_score(sp_model.presence, sp_model.pred)\n",
    "    recall = recall_score(sp_model.presence, sp_model.pred)\n",
    "    prec = precision_score(sp_model.presence, sp_model.pred)\n",
    "    ax.set_title('{} {}: acc={}, f1={}, r={}, p={}'.format(\n",
    "        title, name, round(acc, 2), round(f1, 2), round(recall, 2), round(prec, 2)), loc=\"left\")\n",
    "\n",
    "    sp_model.plot(ax=ax,\n",
    "              column='confussion_labels',\n",
    "              alpha=0.9,\n",
    "              edgecolor='w',\n",
    "              legend=True,\n",
    "              categorical=True,\n",
    "              cmap=my_cmap)\n",
    "    ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bioclim_groups = {'Bioclim': 'root_bioclim'}\n",
    "sdms_abio_df = full_analysis(analysis_res = 64,\n",
    "                             truth_shape = iucn_shp,\n",
    "                             bioclim_groups = bioclim_groups,\n",
    "                             checkpoints_prefix = 'bioclim_{}_'.format(64),\n",
    "                             load_check = 447)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, figsize=(6, 4))\n",
    "species_sdm = sdms_abio_df.groupby('species')\n",
    "species_sdm = species_sdm.get_group('Alouatta palliata')\n",
    "plot_confusion_map(species_sdm, name='Alouatta palliata', ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot_maps_comparision\n",
    "\n",
    "Esta función presenta lado a lado los mapas de uno y otro modelo. Los mapas que se presentan son una selección utilizando el score f1 de una de los modelos. En concreto, la función obtiene los mejores, los peores y los modelos intermedios del modelo *sort_by_model* y muestra los mapas correspondientes, para el modelo elejido y los otros modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_maps_comparision(results, sort_by_model = 0):\n",
    "    ref_model = results[sort_by_model]\n",
    "    stats = get_stats_per_species(ref_model)\n",
    "    stats_df = pd.DataFrame(stats)\n",
    "    quant_size = 0.1\n",
    "    \n",
    "    low, mid_0, mid_1, top = stats_df.f1.quantile([quant_size, 0.5, 0.5 + quant_size, 1 - quant_size])\n",
    "    \n",
    "    low_f1_sp = stats_df[stats_df.f1 <= low].sort_values(by='f1', ascending=True).iloc[:4]\n",
    "    mid_f1_sp = stats_df[stats_df.f1.between(mid_0, mid_1)].sort_values(by='f1', ascending=True).iloc[:4]\n",
    "    top_f1_sp = stats_df[stats_df.f1 >= top].sort_values(by='f1', ascending=False).iloc[:4]\n",
    "\n",
    "    \n",
    "    flatui = ['#ca0020','#f4a582','#92c5de','#0571b0']\n",
    "    my_cmap = ListedColormap(sns.color_palette(flatui).as_hex())\n",
    "    \n",
    "    nrows = 3\n",
    "    ncols = len(results)\n",
    "    \n",
    "    f, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(20, nrows*4))\n",
    "    ref_grouping = ref_model.groupby('species')\n",
    "    other_models_grps = [model.groupby('species') for i, model in enumerate(results) if i != sort_by_model]\n",
    "    \n",
    "    axes = axes.flat\n",
    "    ax_num = 0\n",
    "\n",
    "    # Plot worst performance maps\n",
    "    for name in low_f1_sp.name:\n",
    "        ref_group = ref_grouping.get_group(name)\n",
    "\n",
    "        if ax_num >= len(axes):\n",
    "            break\n",
    "        \n",
    "        ax = axes[ax_num]\n",
    "        ax_num += 1\n",
    "        plot_confusion_map(ref_group, ax, name=name, title=\"Worst\")\n",
    "        \n",
    "        for model in other_models_grps:\n",
    "            if ax_num >= len(axes):\n",
    "                break\n",
    "        \n",
    "            ax = axes[ax_num]\n",
    "            ax_num += 1\n",
    "\n",
    "            if name in model.groups.keys():\n",
    "                grp = model.get_group(name)\n",
    "                plot_confusion_map(grp, ax, name=name, title=\"Worst\")\n",
    "    f.tight_layout()\n",
    "\n",
    "    f, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(20, nrows*4))\n",
    "    \n",
    "    axes = axes.flat\n",
    "    ax_num = 0\n",
    "\n",
    "    # Plot middle performance maps\n",
    "    for name in mid_f1_sp.name:\n",
    "        ref_group = ref_grouping.get_group(name)\n",
    "\n",
    "        if ax_num >= len(axes):\n",
    "            break\n",
    "        \n",
    "        ax = axes[ax_num]\n",
    "        ax_num += 1\n",
    "        plot_confusion_map(ref_group, ax, name=name, title=\"Middle\")\n",
    "        \n",
    "        for model in other_models_grps:\n",
    "            if ax_num >= len(axes):\n",
    "                break\n",
    "        \n",
    "            ax = axes[ax_num]\n",
    "            ax_num += 1\n",
    "\n",
    "            grp = model.get_group(name)\n",
    "            plot_confusion_map(grp, ax, name=name, title=\"Middle\")\n",
    "\n",
    "    f.tight_layout()\n",
    "\n",
    "    f, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(20, nrows*4))\n",
    "    \n",
    "    axes = axes.flat\n",
    "    ax_num = 0\n",
    "    # Plot best performance maps\n",
    "    for name in top_f1_sp.name:\n",
    "        ref_group = ref_grouping.get_group(name)\n",
    "\n",
    "        if ax_num >= len(axes):\n",
    "            break\n",
    "        \n",
    "        ax = axes[ax_num]\n",
    "        ax_num += 1\n",
    "        plot_confusion_map(ref_group, ax, name=name, title=\"Best\")\n",
    "        \n",
    "        for model in other_models_grps:\n",
    "            if ax_num >= len(axes):\n",
    "                break\n",
    "        \n",
    "            ax = axes[ax_num]\n",
    "            ax_num += 1\n",
    "\n",
    "            grp = model.get_group(name)\n",
    "            plot_confusion_map(grp, ax, name=name, title=\"Best\")\n",
    "    f.tight_layout()\n",
    "\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "biotic_groups = {'Animalia': 'reinovalido', 'Plantae': 'reinovalido'}\n",
    "analysis_res = 64\n",
    "sdms_plant_anim_df = full_analysis(analysis_res = analysis_res,\n",
    "                                   truth_shape = iucn_shp,\n",
    "                                   bioclim_groups = bioclim_groups,\n",
    "                                   biotic_groups = biotic_groups,\n",
    "                                   checkpoints_prefix = 'bioclim_snib_{}_'.format(analysis_res),\n",
    "                                   verbose = True,\n",
    "                                   load_check = 398,\n",
    "                                   n = 398)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_maps_comparision([sdms_abio_df, sdms_plant_anim_df], sort_by_model=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot_bottom_mid_top_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bottom_mid_top_maps(smds_df, quant_size):\n",
    "    stats = get_stats_per_species(smds_df)\n",
    "    stats_df = pd.DataFrame(stats)\n",
    "    \n",
    "    low, mid_0, mid_1, top = stats_df.f1.quantile([quant_size, 0.5, 0.5 + quant_size, 1 - quant_size])\n",
    "    \n",
    "    low_f1_sp = stats_df[stats_df.f1 <= low]\n",
    "    mid_f1_sp = stats_df[stats_df.f1.between(mid_0, mid_1)]\n",
    "    top_f1_sp = stats_df[stats_df.f1 >= top]\n",
    "\n",
    "    plot_confussion_maps(smds_df[smds_df.species.isin(low_f1_sp.name)], 6, 'Lowest f1')\n",
    "    plot_confussion_maps(smds_df[smds_df.species.isin(mid_f1_sp.name)], 6, 'Middle f1')\n",
    "    plot_confussion_maps(smds_df[smds_df.species.isin(top_f1_sp.name)], 6, 'Top f1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get_stats_per_species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats_per_species(sdms_df):\n",
    "    stats = []\n",
    "    sp_grp = sdms_df.groupby('species')\n",
    "    for name, grp in sp_grp:\n",
    "        acc = accuracy_score(grp.presence, grp.pred)\n",
    "        f1 = f1_score(grp.presence, grp.pred)\n",
    "        recall = recall_score(grp.presence, grp.pred)\n",
    "        prec = precision_score(grp.presence, grp.pred)\n",
    "\n",
    "        stats.append({'acc': acc, 'f1': f1, 'recall': recall, 'precision': prec, 'name': name})\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## full_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_analysis(analysis_res,\n",
    "                  truth_shape,\n",
    "                  n = None,\n",
    "                  grid_dir = 'grids/',\n",
    "                  bioclim_groups = {},\n",
    "                  biotic_groups = {}, \n",
    "                  verbose = False,\n",
    "                  checkpoints_frq = None,\n",
    "                  checkpoints_prefix = '',\n",
    "                  load_check = None,\n",
    "                  graphics = False):\n",
    "        \n",
    "    grid_path = os.path.join(grid_dir, \"mx_grid_{}km.json\".format(analysis_res))\n",
    "    grid = gpd.read_file(grid_path)\n",
    "\n",
    "    # obtener grid con la resolucion que se necesita e intersecar grid con modelos de iucn\n",
    "    sp_cells = get_grid_iucn_intersection(grid_dir, analysis_res, truth_shape)\n",
    "    \n",
    "    if not n:\n",
    "        n = len(sp_cells)\n",
    "    if checkpoints_frq < 0:\n",
    "        checkpoints_frq = None\n",
    "\n",
    "    sdms_df = evaluate_sdms(api_url, sp_cells, grid,\n",
    "                            analysis_res, start = 0, end = n,\n",
    "                            bioclim_groups = bioclim_groups, \n",
    "                            biotic_groups = biotic_groups,\n",
    "                            verbose = verbose,\n",
    "                            checkpoints_frq = checkpoints_frq,\n",
    "                            checkpoints_prefix = checkpoints_prefix,\n",
    "                            load_check = load_check)\n",
    "    \n",
    "    if graphics:\n",
    "        print_eval_stats(sdms_df)\n",
    "        plot_confussion_maps(sdms_df, 20)\n",
    "            \n",
    "    return sdms_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get_comparison_sdms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comparison_sdms(analysis_res, load_bioclim_check = None, load_plant_anim_check = None):\n",
    "    checkpoints_frq = 5\n",
    "    \n",
    "    bioclim_groups = {'Bioclim': 'root_bioclim'}\n",
    "    sdms_abio_df = full_analysis(analysis_res = analysis_res,\n",
    "                                 truth_shape = iucn_shp,\n",
    "                                 bioclim_groups = bioclim_groups,\n",
    "                                 checkpoints_frq = checkpoints_frq,\n",
    "                                 checkpoints_prefix = 'bioclim_{}_'.format(analysis_res),\n",
    "                                 load_check = load_bioclim_check)\n",
    "\n",
    "#    biotic_groups = {'Plantae': 'reinovalido'}\n",
    "#    sdms_plantae_df = full_analysis(analysis_res = analysis_res,\n",
    "#                                    truth_shape = iucn_shp,\n",
    "#                                    bioclim_groups = bioclim_groups,\n",
    "#                                    biotic_groups = biotic_groups,\n",
    "#                                    verbose = True)\n",
    "    \n",
    "    biotic_groups = {'Animalia': 'reinovalido', 'Plantae': 'reinovalido'}\n",
    "    sdms_plant_anim_df = full_analysis(analysis_res = analysis_res,\n",
    "                                       truth_shape = iucn_shp,\n",
    "                                       bioclim_groups = bioclim_groups,\n",
    "                                       biotic_groups = biotic_groups,\n",
    "                                       checkpoints_frq = checkpoints_frq,\n",
    "                                       checkpoints_prefix = 'bioclim_snib_{}_'.format(analysis_res),\n",
    "                                       load_check = load_plant_anim_check)\n",
    "    \n",
    "    return sdms_abio_df, sdms_plant_anim_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compare_eval_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_eval_stats(results):\n",
    "    for i, sdms_df in enumerate(results):\n",
    "        title = 5*'-' + \"Model {} \" + 20*'-'\n",
    "        fig = print_confusion_matrix(confusion_matrix(sdms_df.presence, sdms_df.pred), class_names=[0, 1])\n",
    "        plt.show(fig)\n",
    "        \n",
    "        print(title.format(i))\n",
    "        print('Accuracy: {}'.format(accuracy_score(sdms_df.presence, sdms_df.pred)))\n",
    "        print('F1 score: {}'.format(f1_score(sdms_df.presence, sdms_df.pred)))\n",
    "        print('Recall: {}'.format(recall_score(sdms_df.presence, sdms_df.pred)))\n",
    "        print('Precision: {}'.format(precision_score(sdms_df.presence, sdms_df.pred)))\n",
    "        print('\\n clasification report: \\n{}'.format(classification_report(sdms_df.presence, sdms_df.pred)))\n",
    "        \n",
    "    for i, sdms_df in enumerate(results):\n",
    "        title = 5*'-' + \"Model {} \" + 20*'-'\n",
    "        print(title.format(i))\n",
    "        stats = get_stats_per_species(sdms_df)\n",
    "        df = pd.DataFrame(stats)\n",
    "        df_test = pd.melt(df[['f1', 'acc', 'recall', 'precision']], var_name=['estadistica'], value_name='valor')\n",
    "        g = sns.FacetGrid(df_test, col='estadistica', size=4)\n",
    "        g.map(sns.distplot, 'valor', bins=10, kde=True, rug=True)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## print_confusion_matrix\n",
    "Fuente: https://gist.github.com/shaypal5/94c53d765083101efc0240d776a23823"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_confusion_matrix(confusion_matrix, class_names, figsize = (10,7), fontsize=14):\n",
    "    \"\"\"Prints a confusion matrix, as returned by sklearn.metrics.confusion_matrix, as a heatmap.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    confusion_matrix: numpy.ndarray\n",
    "        The numpy.ndarray object returned from a call to sklearn.metrics.confusion_matrix. \n",
    "        Similarly constructed ndarrays can also be used.\n",
    "    class_names: list\n",
    "        An ordered list of class names, in the order they index the given confusion matrix.\n",
    "    figsize: tuple\n",
    "        A 2-long tuple, the first value determining the horizontal size of the ouputted figure,\n",
    "        the second determining the vertical size. Defaults to (10,7).\n",
    "    fontsize: int\n",
    "        Font size for axes labels. Defaults to 14.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    matplotlib.figure.Figure\n",
    "        The resulting confusion matrix figure\n",
    "    \"\"\"\n",
    "    df_cm = pd.DataFrame(\n",
    "        confusion_matrix, index=class_names, columns=class_names, \n",
    "    )\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    try:\n",
    "        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\", cmap=\"YlGnBu\")\n",
    "    except ValueError:\n",
    "        raise ValueError(\"Confusion matrix values must be integers.\")\n",
    "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n",
    "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis a 64 km\n",
    "## Descripción\n",
    "\n",
    "Comparamos dos modelos: \n",
    "\n",
    "* el primero usando sólo covariables Bioclim\n",
    "* el segundo usando como covariables: Bioclim; todas las especies de plantas en el SNIB; y todas las especies de animales en el SNIB. Para las especies consideramos sólo especies que ocupan mínimo cinco celdas de la malla. \n",
    "\n",
    "Las variables Bioclim las convertimos previamente a variables binarias de presencia por decil, es decir, para cada variable (p.ej temperatura promedio anual) obtenemos los deciles (rangos de temperatura que contienen el diez por ciento de los valores presentes en la capa) y cada rango de decil se convierte en una variable de presencia/ausencia.\n",
    "\n",
    "## Resultados\n",
    "\n",
    "### Desempeño promedio\n",
    "\n",
    "Presentamos primero estadísticas generales de desempeño tomando como la verdad los mapas de IUCN.\n",
    "\n",
    "* La gran diferencia es en el número de verdaderos negativos promedio, con sólo variables climáticas se tienen 160,222 verdaderos negativos, con climáticas más SNIB tenemos 222,891.\n",
    "* También hay una diferencia en los verdaderos positivos aunque menor en proporción, en este caso, el modelo con bioclim tiene más, obteniendo 57,110 contra 52,282 del modelo con SNIB.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sdms64_abio_df, sdms64_full_bio = get_comparison_sdms(64, load_plant_anim_check=446)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_eval_stats([sdms64_abio_df, sdms64_full_bio])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_eval_stats(sdms64_abio_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_eval_stats(sdms64_mammalia_magnolio_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print_eval_stats(sdms64_reinos_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparación de mapas de confusión\n",
    "\n",
    "En esta sección presentamos los 6 peores, 6 intermadio, y los 6 mejores mapas para cada modelo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grps = sdms64_full_bio.groupby('species')\n",
    "grps = sdms64_abio_df.groupby('species')\n",
    "sdms64_full_bio[sdms64_full_bio.species == 'Ursus arctos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_maps_comparision([sdms64_abio_df, sdms64_full_bio])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_maps_comparision([sdms64_abio_df, sdms64_full_bio], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los siguientes mapas muestran los peores modelos (mapas 1 a 6), modelos intermedios (mapas 7 a 12), y los mejores modelos (mapas 13 a 18), con respecto al score f1.\n",
    "\n",
    "$$ f1 = \\frac{2}{\\frac{1}{Precision} + \\frac{1}{Recall}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_res = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "variables": {
     "analysis_res": "32"
    }
   },
   "source": [
    "# Análisis a {{analysis_res}} km\n",
    "## Descripción\n",
    "\n",
    "Mismo que el anterior pero a {{analysis_res}} km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sdms32_abio_df, sdms32_full_bio = get_comparison_sdms(analysis_res,\n",
    "                                                      load_plant_anim_check=128,\n",
    "                                                      load_bioclim_check=447)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados\n",
    "\n",
    "### Desempeño promedio\n",
    "\n",
    "Presentamos primero estadísticas generales de desempeño tomando como la verdad los mapas de IUCN.\n",
    "\n",
    "* La gran diferencia es en el número de verdaderos negativos promedio, con sólo variables climáticas se tienen 160,222 verdaderos negativos, con climáticas más SNIB tenemos 222,891.\n",
    "* También hay una diferencia en los verdaderos positivos aunque menor en proporción, en este caso, el modelo con bioclim tiene más, obteniendo 57,110 contra 52,282 del modelo con SNIB.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "compare_eval_stats([sdms32_abio_df, sdms32_full_bio])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_maps_comparision([sdms32_abio_df, sdms32_full_bio], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_maps_comparision([sdms32_abio_df, sdms32_full_bio], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_res = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "variables": {
     "analysis_res": "16"
    }
   },
   "source": [
    "# Análisis a {{analysis_res}} km\n",
    "## Descripción\n",
    "\n",
    "Mismo que el anterior pero a {{analysis_res}} km\n",
    "\n",
    "## Resultados\n",
    "\n",
    "### Desempeño promedio\n",
    "\n",
    "Presentamos primero estadísticas generales de desempeño tomando como la verdad los mapas de IUCN.\n",
    "\n",
    "* La gran diferencia es en el número de verdaderos negativos promedio, con sólo variables climáticas se tienen 160,222 verdaderos negativos, con climáticas más SNIB tenemos 222,891.\n",
    "* También hay una diferencia en los verdaderos positivos aunque menor en proporción, en este caso, el modelo con bioclim tiene más, obteniendo 57,110 contra 52,282 del modelo con SNIB.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdms16_abio_df, sdms16_full_bio = get_comparison_sdms(analysis_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_eval_stats([sdms16_abio_df, sdms16_full_bio])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_maps_comparision([sdms16_abio_df, sdms16_full_bio], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_maps_comparision([sdms32_abio_df, sdms32_full_bio], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis con todas las especies (439) a 64, 32 y 16 km"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo con variables climáticas (WorldClim 1.4), registros de mamíferos (clase Mammalia) y plantas con flor (clase Magnoliopsida)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 64 km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bioclim_groups = {'Bioclim': 'root_bioclim'}\n",
    "biotic_groups = {'Mammalia': 'clasevalida', 'Magnoliopsida': 'clasevalida'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%time sdms64_df = full_analysis(analysis_res=64, truth_shape=iucn_shp, bioclim_groups=bioclim_groups, biotic_groups=biotic_groups, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_eval_stats(sdms64_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confussion_maps(sdms64_df, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = []\n",
    "sp_grp = sdms_df.groupby('species')\n",
    "for name, grp in sp_grp:\n",
    "    acc = accuracy_score(grp.presence, grp.pred)\n",
    "    f1 = f1_score(grp.presence, grp.pred)\n",
    "    recall = recall_score(grp.presence, grp.pred)\n",
    "    prec = precision_score(grp.presence, grp.pred)\n",
    "    \n",
    "    stats.append({'acc': acc, 'f1': f1, 'recall': recall, 'precision': prec, 'name': name})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(stats)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.melt(df[['f1', 'acc', 'recall', 'precision']], var_name=['estadistica'], value_name='valor')\n",
    "\n",
    "g = sns.FacetGrid(df_test, col='estadistica', size=4)\n",
    "g.map(sns.distplot, 'valor', bins=10, kde=True, rug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 32 km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time sdms32_df = full_analysis(analysis_res=64, truth_shape=iucn_shp, bioclim_groups=bioclim_groups, biotic_groups=biotic_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_eval_stats(sdms32_df)\n",
    "plot_confussion_maps(sdms32_df, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = []\n",
    "sp_grp = sdms32_df.groupby('species')\n",
    "for name, grp in sp_grp:\n",
    "    acc = accuracy_score(grp.presence, grp.pred)\n",
    "    f1 = f1_score(grp.presence, grp.pred)\n",
    "    recall = recall_score(grp.presence, grp.pred)\n",
    "    prec = precision_score(grp.presence, grp.pred)\n",
    "    \n",
    "    stats.append({'acc': acc, 'f1': f1, 'recall': recall, 'precision': prec, 'name': name})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(stats)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.melt(df[['f1', 'acc', 'recall', 'precision']], var_name=['estadistica'], value_name='valor')\n",
    "\n",
    "g = sns.FacetGrid(df_test, col='estadistica', size=4)\n",
    "g.map(sns.distplot, 'valor', bins=10, kde=True, rug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16 km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time sdms16_df = full_analysis(analysis_res=64, truth_shape=iucn_shp, bioclim_groups=bioclim_groups, biotic_groups=biotic_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_eval_stats(sdms16_df)\n",
    "plot_confussion_maps(sdms16_df, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = []\n",
    "sp_grp = sdms16_df.groupby('species')\n",
    "for name, grp in sp_grp:\n",
    "    acc = accuracy_score(grp.presence, grp.pred)\n",
    "    f1 = f1_score(grp.presence, grp.pred)\n",
    "    recall = recall_score(grp.presence, grp.pred)\n",
    "    prec = precision_score(grp.presence, grp.pred)\n",
    "    \n",
    "    stats.append({'acc': acc, 'f1': f1, 'recall': recall, 'precision': prec, 'name': name})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(stats)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.melt(df[['f1', 'acc', 'recall', 'precision']], var_name=['estadistica'], value_name='valor')\n",
    "\n",
    "g = sns.FacetGrid(df_test, col='estadistica', size=4)\n",
    "g.map(sns.distplot, 'valor', bins=10, kde=True, rug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo con variables climáticas (WorldClim 1.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bioclim_groups = {'root_bioclim': 'Bioclim'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 64 km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time sdms64_abio_df = full_analysis(analysis_res=64, truth_shape=iucn_shp, bioclim_groups=bioclim_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confussion_maps(sdms64_abio_df, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_eval_stats(sdms64_abio_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = get_stats_per_species(sdms64_abio_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 32 Km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time sdms32_abio_df = full_analysis(analysis_res=32, truth_shape=iucn_shp, bioclim_groups=bioclim_groups, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confussion_maps(sdms32_abio_df, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = get_stats_per_species(sdms32_abio_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowest_f1 = df[df.f1 <= df.quantile([.02, .45, .55, .95]).f1.iloc[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confussion_maps(sdms32_abio_df[sdms32_abio_df.species.isin(lowest_f1.name)], 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confussion_maps(sdms32_abio_df[sdms32_abio_df.species.isin(lowest_f1.name)], 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highest_f1 = df[df.f1 >= df.quantile([.02, .45, .55, .98]).f1.iloc[3]]\n",
    "plot_confussion_maps(sdms32_abio_df[sdms32_abio_df.species.isin(highest_f1.name)], 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "midd_f1 = df[(df.f1.between(df.quantile([.50, .52]).f1.iloc[0], df.quantile([.50, .52]).f1.iloc[1]))]\n",
    "plot_confussion_maps(sdms32_df[sdms32_df.species.isin(midd_f1.name)], 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16 km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time sdms16_abio_df = full_analysis(analysis_res=16, truth_shape=iucn_shp, bioclim_groups=bioclim_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_eval_stats(sdms16_abio_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analisis con todos los animales y todas las plantas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bioclim_groups = {'Bioclim': 'root_bioclim'}\n",
    "biotic_groups = {'Animalia': 'reinovalido', 'Plantae': 'reinovalido'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sdms64_reinos_df = full_analysis(analysis_res = 64,\n",
    "                                 truth_shape = iucn_shp,\n",
    "                                 bioclim_groups = bioclim_groups,\n",
    "                                 biotic_groups = biotic_groups,\n",
    "                                 verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_eval_stats(sdms64_reinos_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los siguientes mapas muestran los peores modelos (mapas 1 a 6), modelos intermedios (mapas 7 a 12), y los mejores modelos (mapas 13 a 18), con respecto al score f1.\n",
    "\n",
    "$$ f1 = \\frac{2}{\\frac{1}{Precision} + \\frac{1}{Recall}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_bottom_mid_top_maps(sdms64_reinos_df, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sdms32_reinos_df = full_analysis(analysis_res = 32,\n",
    "                                 truth_shape = iucn_shp,\n",
    "                                 bioclim_groups = bioclim_groups,\n",
    "                                 biotic_groups = biotic_groups,\n",
    "                                 verbose = True,\n",
    "                                 checkpoints_frq = 1,\n",
    "                                 load_check = 230)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print_eval_stats(sdms32_reinos_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bottom_mid_top_maps(sdms32_reinos_df, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdms32_reinos_df_bak = sdms32_reinos_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def species_df_list_to_dict(sdm_dfs): \n",
    "    sdms_dict = {}\n",
    "\n",
    "    for sdm in sdm_dfs:\n",
    "        name = sdm.species.unique()[0]\n",
    "\n",
    "        if not sdms_dict.has_key(name):\n",
    "            sdms_dict[name] = sdm\n",
    "    \n",
    "    return sdms_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdms16_reinos_df = full_analysis(analysis_res=16,\n",
    "                                 truth_shape=iucn_shp,\n",
    "                                 bioclim_groups=bioclim_groups,\n",
    "                                 biotic_groups=biotic_groups,\n",
    "                                 checkpoints_frq=5,\n",
    "                                 load_check=37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "toc = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "102px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "334px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
